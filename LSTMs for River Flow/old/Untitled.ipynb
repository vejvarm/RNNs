{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the network\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# number of iterations in each epoch\n",
    "n_iter = int(np.rint((len(x_train)-delay)//batch_size)) # round to nearest integer\n",
    "n_iter_test = int(np.rint((len(x_test)-delay)//batch_size))\n",
    "n_iter_validation = int(np.rint((len(x_validation)-delay)//batch_size))\n",
    "\n",
    "# function for generating the time-series batches\n",
    "def create_batch(x_data,y_data,batch_size,delay,input_size,index):\n",
    "    \n",
    "    x_batch = np.zeros([batch_size,delay,input_size])\n",
    "    y_batch = np.zeros([batch_size,num_classes])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        x_batch[i,:,:] = np.reshape(x_data[index*batch_size+i:index*batch_size+i+delay],(delay,num_classes))\n",
    "        y_batch[i,:] = np.reshape(y_data[index*batch_size+delay+i+1],(1,num_classes))\n",
    "        \n",
    "    return x_batch, y_batch\n",
    "\n",
    "def run_model(inputs,labels,n_iter,train=False,prediction_val):\n",
    "    for i in range(n_iter):\n",
    "        # training batch\n",
    "        x_batch, y_batch = create_batch(inputs,labels,batch_size,delay,input_size,i)\n",
    "\n",
    "        feed_dict = {x: x_batch, y: y_batch}\n",
    "        \n",
    "        # train the net on the data\n",
    "        if train:\n",
    "            session.run(optimizer,feed_dict=feed_dict) # run the optimization on the current batch\n",
    "\n",
    "        loss_val, prediction_val = session.run((loss, prediction), feed_dict=feed_dict)\n",
    "\n",
    "        # on the last epoch\n",
    "        if epoch == n_epochs - 1:       \n",
    "            # save the batch predictions to a list\n",
    "            prediction_list.extend(prediction_val)    \n",
    "    \n",
    "\n",
    "# list for prediction results\n",
    "prediction_list = []\n",
    "prediction_list_test = []\n",
    "prediction_list_validation = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init) # initialize variables\n",
    "    for epoch in range(n_epochs):\n",
    "        # TRAINING\n",
    "        for i in range(n_iter):\n",
    "            # training batch\n",
    "            x_batch, y_batch = create_batch(x_train,y_train,batch_size,delay,input_size,i)\n",
    "\n",
    "            feed_dict = {x: x_batch, y: y_batch}\n",
    "            session.run(optimizer,feed_dict=feed_dict) # run the optimization on the current batch\n",
    "\n",
    "            loss_val, prediction_val = session.run((loss, prediction), feed_dict=feed_dict)\n",
    "\n",
    "            # on the last epoch\n",
    "            if epoch == n_epochs - 1:       \n",
    "                # save the batch predictions to a list\n",
    "                prediction_list.extend(prediction_val)\n",
    "        \n",
    "        # TESTING\n",
    "        for i in range(n_iter_test):\n",
    "            # testing batch\n",
    "            x_batch, y_batch = create_batch(x_test,y_test,batch_size,delay,input_size,i)\n",
    "            \n",
    "            # get the loss and predictions for current testing batch\n",
    "            feed_dict = {x: x_batch, y: y_batch}\n",
    "            loss_val_test, prediction_val_test = session.run((loss, prediction), feed_dict=feed_dict)\n",
    "            \n",
    "            # on the last epoch\n",
    "            if epoch == n_epochs - 1:       \n",
    "                # save the batch predictions to a list\n",
    "                prediction_list_test.extend(prediction_val_test)            \n",
    "            \n",
    "        # increment global step for decaying learning rate at each epoch\n",
    "        step = session.run(increment_global_step_op)\n",
    "\n",
    "        # Printing the results at every 1000 epochs\n",
    "        if epoch % (n_epochs//10) == 0:\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"TRAINING:\")\n",
    "            print(\"Loss: {}\".format(loss_val))\n",
    "            print(\"TEST:\")\n",
    "            print(\"Loss: {}\".format(loss_val_test))\n",
    "            print(\"________________________________\")\n",
    "        \n",
    "    # run the trained net on VALIDATION time-series\n",
    "    for i in range(n_iter_validation):\n",
    "        # validation batch\n",
    "        x_batch, y_batch = create_batch(x_validation,y_validation,batch_size,delay,input_size,i)\n",
    "\n",
    "        # get the loss and predictions for the validation batch\n",
    "        feed_dict = {x: x_batch, y: y_batch}\n",
    "        loss_val_validation, prediction_val_validation = session.run((loss, prediction), feed_dict=feed_dict)\n",
    "\n",
    "        # on the last epoch\n",
    "        if epoch == n_epochs - 1:       \n",
    "            # save the batch predictions to a list\n",
    "            prediction_list_validation.extend(prediction_val_validation)\n",
    "            \n",
    "    print(\"VALIDATION:\")\n",
    "    print(\"Loss: {}\".format(loss_val_validation))\n",
    "    \n",
    "    # save the trained net and variables for later use\n",
    "    saver.save(session, './checkpoints/LSTMforPredictingLabeFlow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
